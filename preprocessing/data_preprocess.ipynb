{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"data_preprocess.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN10Ybm3XBd7jBKSauaVMZI"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"CLnqrUKelggQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1594463934794,"user_tz":-120,"elapsed":25398,"user":{"displayName":"Sizhuo Li","photoUrl":"","userId":"17674686512784191090"}},"outputId":"444ab6d2-dda1-45d3-8892-11fe6038cd0d"},"source":["import os\n","from google.colab import drive\n","drive.mount('/content/gdrive/', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jBfkXHAel4AL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594463938483,"user_tz":-120,"elapsed":2231,"user":{"displayName":"Sizhuo Li","photoUrl":"","userId":"17674686512784191090"}},"outputId":"92e462cc-090c-4886-80a1-72c3dde92ffb"},"source":["os.chdir('/content/gdrive/My Drive/final_files/')\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["classification\traw_data  README.md  translation\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lzjhoiP7jY7X","colab_type":"code","colab":{}},"source":["import sys\n","sys.path.append('raw_data/')\n","from preprocess import data_preprocess"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Duckz-6BUjeU","colab_type":"text"},"source":["STEP 0. Setup pre-process configs"]},{"cell_type":"code","metadata":{"id":"DYlUP8TlzQl7","colab_type":"code","colab":{}},"source":["class configs():\n","    # path to folders containing original images\n","    path_to_img1 = 'raw_data/img/'\n","    path_to_img2 = 'raw_data/img_2nd/pa_ost/'\n","    # path to store cropped patches\n","    dest = 'raw_data/cropped_patches/'\n","    # path to place dataset for translation\n","    trans_dataset = 'translation/data/'\n","    # path to place dataset for classifictaion\n","    class_dataset = 'classification/data/'\n","    # path to csv files\n","    path_to_meta = path_to_img2 + 'metadata.csv'\n","    path_to_coor = 'raw_data/coord_data.csv'\n","    path_to_oste = 'raw_data/osteophyte_data.csv'\n","    # cropping size\n","    size = 180\n","    # whether to flip some patches\n","    mirror = 1\n","    # whether to apply histogram equalization\n","    equal = 1\n","    # whether to use only severest samples (labeled 3)\n","    only_sever = 1\n","    # whether to apply binary classification\n","    binary = 1\n","    # ratio for training set for translation\n","    trans_ratio = 0.9\n","    # train-val-test ratio for classification\n","    classify_ratio = (0.8, 0.1, 0.1)\n","\n","conf = configs()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g4fHeaKjmlJt","colab_type":"code","colab":{}},"source":["datap = data_preprocess(conf)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z9KbxRzpUpuI","colab_type":"text"},"source":["STEP 1. Crop images in first folder"]},{"cell_type":"code","metadata":{"id":"G71m0tjOcZRb","colab_type":"code","colab":{}},"source":["datap.crop_1st(conf)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0bbskYgDUub9","colab_type":"text"},"source":["STEP 2. Crop images in second folder\n","\n"]},{"cell_type":"code","metadata":{"id":"Jj68PNd0cbXY","colab_type":"code","colab":{}},"source":["datap.crop_2nd(conf)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PLnXcJwFUxla","colab_type":"text"},"source":["STEP 3. Prepare dataset for translation task"]},{"cell_type":"code","metadata":{"id":"CEkP7w-IiUAM","colab_type":"code","colab":{}},"source":["datap.translation_split(conf)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vx8FFRuMU1y_","colab_type":"text"},"source":["STEP 4. Prepare dataset for classification task"]},{"cell_type":"code","metadata":{"id":"9IuuMYtn6L9c","colab_type":"code","colab":{}},"source":["datap.classification_split(conf)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RGJvyi5mfHO5","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XXQOa2qFg0j6","colab_type":"text"},"source":["ADDITIONAL EXPERIMENTS\n","\n","1. IF NOT ONLT SEVERE SAMPLES (ADD IMG1 AND IMG2 TO THE DOMAIN B)"]},{"cell_type":"code","metadata":{"id":"7RzJfN7ZhD4T","colab_type":"code","colab":{}},"source":["class configs():\n","    # path to folders containing original images\n","    path_to_img1 = 'raw_data/img/'\n","    path_to_img2 = 'raw_data/img_2nd/pa_ost/'\n","    # path to store cropped patches\n","    dest = 'raw_data/cropped_patches'\n","    # path to place dataset for translation\n","    trans_dataset = 'translation/data_0_123/'\n","    # path to place dataset for classifictaion\n","    class_dataset = 'classification/data/'\n","    # path to csv files\n","    path_to_meta = path_to_img2 + 'metadata.csv'\n","    path_to_coor = 'raw_data/coord_data.csv'\n","    path_to_oste = 'raw_data/osteophyte_data.csv'\n","    # cropping size\n","    size = 180\n","    # whether to flip some patches\n","    mirror = 1\n","    # whether to apply histogram equalization\n","    equal = 1\n","    # whether to use only severest samples (labeled 3)\n","    only_sever = 0\n","    # whether to apply binary classification\n","    binary = 1\n","    # ratio for training set for translation\n","    trans_ratio = 0.9\n","    # train-val-test ratio for classification\n","    classify_ratio = (0.8, 0.1, 0.1)\n","\n","conf = configs()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BotyexuOhfJX","colab_type":"code","colab":{}},"source":["datap = data_preprocess(conf)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P76XQq2whg5R","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":156},"executionInfo":{"status":"ok","timestamp":1594256360611,"user_tz":-120,"elapsed":9137934,"user":{"displayName":"Sizhuo Li","photoUrl":"","userId":"17674686512784191090"}},"outputId":"3b7d48cb-3ae2-4c7c-be00-ff069deeb230"},"source":["#split data so that train/testA contains img0, train/testB contains img1, img2, img3 \n","datap.translation_split(conf)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 11285/11285 [1:29:54<00:00,  2.09it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["**** Adding label 1, 2, 3 patches to the \"unhealthy\" domain ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 886/886 [06:55<00:00,  2.13it/s]\n","100%|██████████| 1419/1419 [11:09<00:00,  2.12it/s]\n","100%|██████████| 5308/5308 [42:58<00:00,  2.06it/s]"],"name":"stderr"},{"output_type":"stream","text":["Dataset creation finished.\n","Number of samples in trainA is 10157\tNumber of samples in trainB is 6854\tNumber of samples in testA is 1128\tNumber of samples in testB is 759\t\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]}]}